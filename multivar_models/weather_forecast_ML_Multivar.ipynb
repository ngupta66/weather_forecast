{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Mutli-variate Analysis for Weather Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sns.set()\n",
    "DATA_PATH = \"..\\\\data\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a list to store test results\n",
    "test_ar = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy metrics\n",
    "def accuracy_metrics(forecast, actual):\n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n",
    "    mae = np.mean(np.abs(forecast - actual))    # MAE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
    "    print('Mean Absolute Percent Error ', mape, 'Mean Absolute Error', mae, 'Root Mean Square Error (rmse) ' , rmse)\n",
    "    return mape, mae, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning - Weather all Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Vancouver.temperature', 'Vancouver.pressure', 'Vancouver.humidity',\n",
      "       'Vancouver.wind_speed', 'Vancouver.wind_direction',\n",
      "       'Portland.temperature', 'Portland.pressure', 'Portland.humidity',\n",
      "       'Portland.wind_speed', 'Portland.wind_direction',\n",
      "       ...\n",
      "       'Tel Aviv District.latitude', 'Tel Aviv District.longitude',\n",
      "       'Eilat.latitude', 'Eilat.longitude', 'Haifa.latitude',\n",
      "       'Haifa.longitude', 'Nahariyya.latitude', 'Nahariyya.longitude',\n",
      "       'Jerusalem.latitude', 'Jerusalem.longitude'],\n",
      "      dtype='object', length=252)\n",
      "(44460, 252)\n"
     ]
    }
   ],
   "source": [
    "# read 'weather_all.csv'  dataset as a dataframe\n",
    "df = pd.read_csv(DATA_PATH + 'weather_all.csv', low_memory =  False)\n",
    "# Convert index column to datetime dtype.\n",
    "df.datetime = pd.to_datetime(df.datetime, infer_datetime_format = True)\n",
    "df.set_index('datetime', inplace = True)\n",
    "\n",
    "Features = df.columns\n",
    "print(Features)\n",
    "\n",
    "print(df.shape)\n",
    "#print(df.info(verbose = True, null_counts = True))\n",
    "\n",
    "# All data needs to be scaled to a small range like 0 to 1 for the neural\n",
    "# network to work well. Create scalers for the inputs and outputs.\n",
    "\n",
    "df_Scaled = MinMaxScaler(feature_range=(0.1, 1.1)).fit_transform(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44453, 1152)\n",
      "(10, 1152)\n",
      "(44443, 1152)\n"
     ]
    }
   ],
   "source": [
    "lags_size = 6 # 6hrs\n",
    "n_outputs = df.shape[1] - 36 * 2\n",
    "num_samples = df.shape[0] - lags_size - 1\n",
    "a = np.empty((num_samples, lags_size * n_outputs + 36 * 2))\n",
    "y_new = np.empty((num_samples, n_outputs))\n",
    "for i in range(num_samples):\n",
    "    for j in range(n_outputs): \n",
    "        for k in range(lags_size):\n",
    "            a[i][j * lags_size + k] = df_Scaled[i + k][j]\n",
    "        y_new[i][j] = df_Scaled[i+lags_size][j]\n",
    "    for m in range(36 * 2):\n",
    "        a[i][n_outputs * lags_size + m] = df_Scaled[i][n_outputs + m]\n",
    "X_new = pd.DataFrame(a)\n",
    "print(X_new.shape)\n",
    "#print(X_new.info(verbose = True, null_counts = True))\n",
    "\n",
    "\n",
    "# Create Training and Test 80/20 ratio\n",
    "test_size = 10    # 10 hrs for each city\n",
    "training_size = X_new.shape[0] - test_size\n",
    "\n",
    "x_train = X_new.iloc[:training_size]\n",
    "x_test = X_new.iloc[training_size: training_size + test_size]\n",
    "y_train = y_new[:training_size]\n",
    "y_test = y_new[training_size:training_size + test_size]\n",
    "print(x_test.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percent Error  0.3440666998513223 Mean Absolute Error 0.11797807630725914 Root Mean Square Error (rmse)  0.1746045568586359\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(random_state=0, n_estimators = 500, max_depth = None, \n",
    "                              max_features = 20, min_samples_split = 10, min_samples_leaf = 10, bootstrap = False)\n",
    "model_rf = model_rf.fit(x_train, y_train)\n",
    "y_pred_rf = model_rf.predict(x_test)\n",
    "\n",
    "mape, mae, rmse = accuracy_metrics(y_pred_rf, y_test)\n",
    "test_ar.append({'label':'RandomForestRegressor', 'mape' : mape, 'mae': mae,'rmse':rmse})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percent Error  0.20294193334454128 Mean Absolute Error 0.057657808165392815 Root Mean Square Error (rmse)  0.1178985613119973\n"
     ]
    }
   ],
   "source": [
    "model_lr = LinearRegression(fit_intercept = False)\n",
    "model_lr = model_lr.fit(x_train, y_train)\n",
    "y_pred_lr = model_lr.predict(x_test)\n",
    "\n",
    "mape, mae, rmse = accuracy_metrics(y_pred_lr, y_test)\n",
    "test_ar.append({'label':'LinearRegression', 'mape' : mape, 'mae': mae,'rmse':rmse})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'RandomForestRegressor', 'mape': 0.3440666998513223, 'mae': 0.11797807630725914, 'rmse': 0.1746045568586359}, {'label': 'LinearRegression', 'mape': 0.20294193334454128, 'mae': 0.057657808165392815, 'rmse': 0.1178985613119973}]\n"
     ]
    }
   ],
   "source": [
    "print(test_ar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
